{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"anaconda-cloud":{},"checksums":["c25cbc8f297629ccc18d96154b8c28d9","6e7a9036fa1c5b8df5d7f7de35e7ed35","63ba48cba8c253bc88ff021505be1691","4071847c9d54fa3d59530ef6de93f69f","1ed8efad100a2a317c1958b03a31ed6b","1ecbf68cee51d68f77e3f3c2997c3065","c8c07619aaa16363ed3373bb563aec8f","57e964761b631c6f5fc9e4295a7cc21f","036db2d2d84687f1befca7d08aa364f8","ce7b0544db965329e1b6d0824e7fc1d9","3a76d7cce4e9ecdb4fe70737e7879960","562505d567faf02dfc9388e81e89d07b","592f5b67d11c5e222677f796527e04b0","2ac080bab68244f461c30801970f1845","5c5d3147fae28af9597674c3c9497bd8","94983acd918967a199f41f9b5215fcaf","a697eb8356f7a0aefc6eee203e224f45","50ea614f8e94c3d55f0ae8b4200836c7","4e74d999d97b4aec2741417d8e8254e7","af93f2ab7da473408f9710c10bc9a493","8983bab671f34812b678eb4b6ac0389a","eb21cc245fb884ec688d776ad844608a","a32edc2c765c8a628ada9102f8579b78","0102167b600104d3364fd7c245046df5","6f6b68e63a8dc62832e76bf0ec3026e1","4f9760fafa68b2af7a403f73e6994208","b6141cdfda9eef6f31ce24e0443a0524","9d36403bf7c8f716121af7364c26ba9c","870c57e6aa3aa8eb5fe5dee2650999b8","6716898ebc08ee7ce3d7bf4280f33773","23d1d17b2b7a19f3b779c97b0da729f4","4efa4749598a29a65b005da1aa295d67","2f43b42fd833d1e77420a8dae7419000","721c0a1ca60ee2b6db54b43b483177cc","2a92caf98e64c64c492f31f8ff41d133","22d76a2aa58ec57293e15bc7f2fd9196","6178d7990e0e19323f67adfbf4b5bab2","89d63f166823eee810feb9cf5fd43a55","ba85086343acb009f0f9129b7d56d39b","c694cefe367e1a7d44f2063be1ecfc34","a85c09b0a23870148caf9d9de4dae192","4815f45b32e16d1799a8e1e03273b05b","269427d7ea78cd9966bdb71503903fa5","281af13a33563776ddf673c7219d01ac","5d16c34da240c5ca1fb99f909f4e8224","f6258a146317770557e1eec2f378b631","37917c9cbc8a9af27160ad97045b03b7","b87b55a61103fdea7f4167f5ea724ebc","18a1644ad6f74de14c700d0248fd7abf","ccc7ea2306136190f42cf97a7ba1604f","1e41a6fc880bbecbbe91fd59888f81cf","7b6436946486c2ad1d05f4c80d129f75","9dad95aa1028872116fb8daf6043a23f","76276f64628cb1119abd0930e8f818a9","7ac7328447a5d6a1a480e1a13eae02e1","bc94950668261718e1f2df8085de4940","2f43b42fd833d1e77420a8dae7419000","5cf18b1edabd5a0e9b27ba8f0dba4296","3e4e798bebee02accabb5a87e5bbf985","63fc58bdcf0a74a47676feb432a1ba39","166746185543ebae31a67b4b06093766","234f3f7ec6cc3db82bda63e00c37200d","2f43b42fd833d1e77420a8dae7419000","adffa6a4ad420d11eec9bd26535ac434","2f43b42fd833d1e77420a8dae7419000","04caf385398f8d8c7efb140b14f1eaf9","562505d567faf02dfc9388e81e89d07b","77f42904aea5b58b6b11699e293d36c2","bc7c579118924ed5f2ff6bb01db54fa9","0a3116ffe7fe4d7ae8079a2534f84576","fd93a1abbd1ea662152b79cdf69afa03","e8381b9a58ec701e1ef078e1bf93a9c4","183eaaab35aa00c672a0f21eca262853","7256573c68dedaa164ff497832ff6885","2e0e58a3a855bdb88b084abba270d18d","0de20b93bb878d597e59213991465648","2710e90579a63cb78163eee608e98a9e","a29f13882a5630e5615debee592ef3d5","2f43b42fd833d1e77420a8dae7419000","3ffb0ade2c07d473ca536e51a0038827","3e4e798bebee02accabb5a87e5bbf985","7111f75da42c5dc32e8ff64c9cc4e06c","1ec8d50e43e6ef89c56d7204f666c5bf","cdaf384a869b5f98c0cc503a5f361acc","562505d567faf02dfc9388e81e89d07b","ee40e815e285adeb7ba0cc155cea948e","f47e7d89422449e897db76bb1eab41ae","3e4e798bebee02accabb5a87e5bbf985","54366dd7b8a459f6f3df20c3bef3412d","a446d00061da4f9ab86d45206fd2bb1f","6d8daa29d52a3c52e5b1c2d59ac5cedf","3e4e798bebee02accabb5a87e5bbf985","aa60c77adaa7e35c26ad38be921f655c","18a1644ad6f74de14c700d0248fd7abf","7fcdffdfb40f3d75e11b21ed652051b6","2f43b42fd833d1e77420a8dae7419000","f846c1b92bef774bf05f1eb4b0066a81","0de0e05b9b68cd2c592dac263e5eb43d","e4e51b595a2d46ad8b4cf6aba1916063","b38351dd00d349a54817aa0c062388e2","b4ff7c922dcad63e7e456079730f87d1","398be2fe0723d362ffe19ee59afe8e8b","3a734cc7e805653f879a9b8c55bcab3e","0253cae4dd56fd77dfbc9e3c47a081b7","ed898ac60ba4d304a603d685c3a2d2c1","88ad3bc0c47ce0dda509fb3638b2c5e2","68b507c9a05b1a88c3e6b1eeeda1667d","c84dab39db51165c22a9e71f78532afc","2ec6b5fe5b0e03a379bc42aafc75e322","b66889fd32dfd8f2f2f013793f161f71","8151e814f95f52014b3612827f30f6f3","fd93a1abbd1ea662152b79cdf69afa03","fa8a2e421a968444f655b232349d2429","a55ce9af3f38abbc7ca472e4008d53f6","96c00560f02a85f9cfd65c39ee85fb99","d3ee3324bb322a34d1bff5f04ae5a285","a82f708adee6c28869936f2e882714d2","0de20b93bb878d597e59213991465648","c727d71a0bcddfbc272bc9c784df77ff","3e4e798bebee02accabb5a87e5bbf985","c992d5598049ab3c9aceca07c3b57037","2f43b42fd833d1e77420a8dae7419000","c1e46950e801d25ace07cee38b67089c","3e4e798bebee02accabb5a87e5bbf985","d0778cf467c120138b4e8b2826df160a","190b34ba3f714c3be261e85119e0a231","bb2dd86e11375c0db29243d07cc7f7c8","6a9948f562a4cd9e730c84de9a5c2bb2","2b5b3f662b553d93399bb0f499528d49","ee4c62bc541ea490796f81702a318212"],"number_of_pagebreaks":0},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<table align=\"left\" style=\"border-style: hidden\" class=\"table\"> <tr><td class=\"col-md-2\"><img style=\"float: left; width: 200px; height: 200px;\" src=\"../logo.png\" alt=\"Data 140 Logo\" style=\"width: 120px;\"/></td><td><div align=\"left\"><h3 style=\"margin-top: 0;\">Probability for Data Science</h3><h4 style=\"margin-top: 20px;\">UC Berkeley, Spring 2025</h4><p>Michael Xiao and Ani Adhikari</p>CC BY-NC-SA 4.0</div></td></tr></table><!-- not in pdf -->\n\nThis content is protected and may not be shared, uploaded, or distributed.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"from datascience import *\nfrom prob140 import *\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n%matplotlib inline\nfrom scipy import stats\nfrom sympy import *\ninit_printing()\nfrom matplotlib import patches\nfrom mpl_toolkits.mplot3d.axes3d import Axes3D\nimport ipywidgets as widgets\nfrom ipywidgets import interact\n\n# Hide deprecation warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_ellipse(ax, a, b, color, draw_lines=True):\n    ax.add_artist(patches.Ellipse((0, 0), 6 * a, 6 * b, color=color,\n                                  lw=2, fill=False))\n    for x in range(-3, 4):\n        ax.plot([-3 * a, 3 * a], [x * b, x * b],\n                color='k', lw=1)\n        ax.plot([x * a, x * a], [-3 * b, 3 * b],\n                color='k', lw=1)","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def z_to_v(a, b, n=0, **kwargs):\n    m = max(a, b, 1) * 3 + 0.5\n    samples = stats.multivariate_normal.rvs(mean=[0, 0], size=n).reshape((n, 2))\n    \n    def indep_normals(v, w):\n        const = 1 / (2 * np.pi * np.abs(a * b))\n        return const * np.exp(-0.5*((v / a) ** 2 + (w / b)**2))\n    def indep_standard_normals(x,y):\n        const = 1 / (2 * np.pi)\n        return const * np.exp(-0.5 * (x ** 2 + y **2 ))\n\n    x = np.linspace(-m, m, 100)\n    y = np.linspace(-m, m, 100)\n    X, Y = np.meshgrid(x, y)\n\n    f1 = np.vectorize(indep_standard_normals)\n    f2 = np.vectorize(indep_normals)\n\n    Z1 = f1(X, Y)\n    Z2 = f2(X, Y)\n    \n    def plot(azim):\n        fig = plt.figure(figsize=(18, 18))\n        ax1 = fig.add_subplot(221, projection='3d')\n        ax2 = fig.add_subplot(222, projection='3d')\n        ax1.plot_surface(X, Y, Z1, color='blue', **kwargs)\n        ax2.plot_surface(X, Y, Z2, color='gold', **kwargs)\n        z_max = max(Z1.max(), Z2.max())\n        ax1.set_zlim3d(0, z_max) \n        ax2.set_zlim3d(0, z_max)\n        ax1.set_title('$\\mathbf{Z}$')\n        ax1.set_xlabel('$z_1$')\n        ax1.set_ylabel('$z_2$')\n        ax1.set_zlabel('$f(z_1, z_2)$')\n        ax2.set_title('$\\mathbf{V}$')\n        ax2.set_xlabel('$v_1$')\n        ax2.set_ylabel('$v_2$')\n        ax2.set_zlabel('$f_V(v_1, v_2)$')\n        ax1.view_init(20, azim)\n        ax2.view_init(20, azim)\n        ax3 = fig.add_subplot(223)\n        ax4 = fig.add_subplot(224)\n        ax3.set_aspect('equal', adjustable='box') # old version has adjustable='datalim'\n        ax4.set_aspect('equal', adjustable='box')\n        plot_ellipse(ax3, 1, 1, 'blue')\n        ax3.scatter(samples[:, 0], samples[:, 1], s=30)\n        ax3.grid(False)\n        plot_ellipse(ax4, a, b, 'gold')\n        ax4.scatter(samples[:, 0] * a, samples[:, 1] * b, s=30)\n        ax3.set_xlim(-m, m)\n        ax3.set_ylim(-m, m)\n        ax4.set_xlim(-m, m)\n        ax4.set_ylim(-m, m)\n        ax4.grid(False)\n    azimuth_slider = widgets.IntSlider(\n        value=-90,\n        min=-180,\n        max=180,\n        step=15,\n        description='azimuth',\n        continuous_update=False\n    )\n\n    @interact(azim=azimuth_slider)\n    def wrapper(azim):\n        plot(azim)\n        plt.show()","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unit_square_to_rectangle(a, b):\n    plt.axes().set_aspect('equal')\n    plt.xlim(-0.1 + min(a, 0), max(a, 1) + 0.1)\n    plt.xticks(np.arange(min(a, 0), max(a, 1) + 0.1))\n    plt.ylim(-0.1 + min(b, 0), max(b, 1) + 0.1)\n    plt.yticks(np.arange(min(b, 0), max(b, 1) + 0.1))\n    plt.plot([0, 1], [0, 0], color='k', lw=2)\n    plt.plot([0, 0], [0, 1], color='k', lw=2)\n    plt.plot([0, 1], [1, 1], color='k', lw=2)\n    plt.plot([1, 1], [0, 1], color='k', lw=2)\n    plt.plot([0, a], [0, 0], color='gold', lw=2)\n    plt.plot([0, 0], [0, b], color='gold', lw=2)\n    plt.plot([0, a], [b, b], color='gold', lw=2)\n    plt.plot([a, a], [0, b], color='gold', lw=2);","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unit_square_to_parallelogram(a, b):\n    plt.axes().set_aspect('equal')\n    plt.xlim(-0.1 + min(a, 0), max(a, 1) + 0.1)\n    plt.xticks(np.arange(min(a, 0), max(a, 1) + 0.1))\n    plt.ylim(-0.1 + min(a + b, 0, a, b), max(a + b, 1, a, b) + 0.1)\n    plt.yticks(np.arange(min(a + b, 0, a, b), max(a + b, 1, a, b) + 0.1))\n    plt.plot([0, 1], [0, 0], color='k', lw=2)\n    plt.plot([0, 0], [0, 1], color='k', lw=2)\n    plt.plot([0, 1], [1, 1], color='k', lw=2)\n    plt.plot([1, 1], [0, 1], color='k', lw=2)\n    plt.plot([0, 1], [0, a], color='red', lw=2)\n    plt.plot([0, 0], [0, b], color='red', lw=2)\n    plt.plot([1, 1], [a, a + b], color='red', lw=2)\n    plt.plot([0, 1], [b, a + b], color='red', lw=2);","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def z_to_w(a, b, n=0, **kwargs):\n    m = max(3 * (a + b), 4) + 0.5\n    samples = stats.multivariate_normal.rvs(mean=[0, 0], size=n).reshape((n, 2))\n    cov1 = np.identity(2)\n    norm1 = stats.multivariate_normal(cov=cov1)\n    cov2 = np.array([[1, a],[a, a ** 2 + b ** 2]])\n    norm2 = stats.multivariate_normal(cov=cov2)\n    x = np.linspace(-m, m, 100)\n    y = np.linspace(-m, m, 100)\n    X, Y = np.meshgrid(x, y)\n    pos = np.empty(X.shape + (2,))\n    pos[:, :, 0] = X\n    pos[:, :, 1] = Y\n    Z1 = norm1.pdf(pos)\n    Z2 = norm2.pdf(pos)\n    def plot(azim):\n        fig = plt.figure(figsize=(18, 18))\n        ax1 = fig.add_subplot(221, projection='3d')\n        ax2 = fig.add_subplot(222, projection='3d')\n        ax1.plot_surface(X, Y, Z1, color='blue', **kwargs)\n        ax2.plot_surface(X, Y, Z2, color='r', **kwargs)\n        z_max = max(Z1.max(), Z2.max())\n        ax1.set_zlim3d(0, z_max) \n        ax2.set_zlim3d(0, z_max)\n        ax1.set_title('$\\mathbf{Z}$')\n        ax1.set_xlabel('$z_1$')\n        ax1.set_ylabel('$z_2$')\n        ax1.set_zlabel('$f(z_1, z_2)$')\n        ax2.set_title('$\\mathbf{W}$')\n        ax2.set_xlabel('$w_1$')\n        ax2.set_ylabel('$w_2$')\n        ax2.set_zlabel('$f_W(w_1, w_2)$')\n        ax1.set_xlim(-m, m)\n        ax1.set_ylim(-m, m)\n        ax2.set_xlim(-m, m)\n        ax2.set_ylim(-m, m)\n        ax1.view_init(20, azim)\n        ax2.view_init(20, azim)\n        ax1 = fig.add_subplot(223)\n        ax1.set_aspect('equal', adjustable='box') # old version has adjustable='datalim'\n        ax1.set_xlabel('$Z_1$')\n        ax1.set_ylabel('$Z_2$')\n        ax1.scatter(samples[:, 0], samples[:, 1], s=30)\n        plot_ellipse(ax1, 1, 1, 'blue')\n        ax2 = fig.add_subplot(224)\n        ax2.set_aspect('equal', adjustable='box')\n        for x in range(-3, 4):\n            ax2.plot([-3, 3], [-3 * a + b * x, 3 * a + b * x], color='k', lw=1)\n            ax2.plot([x, x], [a * x - 3 * b, a * x + 3 * b], color='k', lw=1)\n        radius = 32 / (a ** 2 + b ** 2) ** 0.5\n        ax2.scatter(samples[:, 0], a * samples[:, 0] + b * samples[:, 1], s=30)\n        ax2.set_xlabel('$W_1$')\n        ax2.set_ylabel('$W_2$')\n        ax1.set_xlim(-m, m)\n        ax1.set_ylim(-m, m)\n        ax2.set_xlim(-m, m)\n        ax2.set_ylim(-m, m)\n        theta = np.linspace(0, 2 * np.pi)\n        x = np.cos(theta)\n        y = np.sin(theta)\n        plt.plot(3 * x, 3 * (a * x + b * y), lw=2, color='r')\n    \n    azimuth_slider = widgets.IntSlider(\n        value=-90,\n        min=-180,\n        max=180,\n        step=15,\n        description='azimuth',\n        continuous_update=False\n    )\n\n    @interact(azim=azimuth_slider)\n    def wrapper(azim):\n        plot(azim)\n        plt.show()","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Lab 8: Introduction to Jointly Normal Vectors (Due Monday, April 21st at 5 PM)","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"## Identify Your Lab Partner ##","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"This is a multiple choice question. Please select **ONE** of following options that best describes how you complete this lab.\n\n- I am doing this lab by myself and I don't have a partner.\n- My partner for this lab is [PARTNER'S NAME] with email [berkeley.edu email address]. [SUBMITTER'S NAME] will submit to Gradescope and add the other partner to the group on Gradescope after submission.\n\nPlease copy and paste **ONE** of above statements and fill in blanks if needed. If you work with a partner, make sure only one of you submit on Gradescope and that the other member of the group is added to the submission on Gradescope. Refer to the bottom of the notebook for submission instructions.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"**Your answer here.**","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"\\newpage","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"The multivariate normal distribution is central to many topics in statistical learning theory. In this lab you will develop the most commonly used formula for the multivariate normal joint density.\n\nThe lab is designed as a sequence of small steps that lead you to the joint distribution of linear combinations of independent standard normal variables. That's the multivariate normal distribution. Random variables with this joint distribution are called *jointly normal*. In class we will study the fundamental properties of this joint distribution and its use in multiple linear regression.\n\nThe lab is just an introduction to the multivariate normal. It's not intended as a thorough account, and you might have questions at the end of it. Keep a note of your questions. I hope that they will be answered once we study the distribution in class.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"**Please make sure you have some paper and a pencil as you do this lab.** It combines algebra, geometry, calculus, linear algebra, and of course probability theory.\n\nWhat you will learn:\n- How to use `SymPy` for linear algebra\n- How to find the joint density of a linear transformation of two variables\n- How to parametrize the joint density of two independent normal variables so that the formula can easily be extended to handle higher dimensions","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"Let's get started with a couple of preliminaries. The first one sets up some standard notation for collections of random variables and their moments. The second one examines the form of the normal density function in one dimension.\n\n## Two Dimensions ##\nWe are used to thinking about a pair of random variables $X$ and $Y$ as a point $(X, Y)$ on the plane. As we move to higher dimensions, it becomes convenient to use matrix representations instead. \n\nThis lab is almost entirely about two dimensions, so the definitions below are about a pair of random variables. All the definitions have obvious extensions to $n$ dimensions for $n > 2$.\n\n### Random Vector ###\nWe will represent random variables $X_1$ and $X_2$ as a column vector.\n$$\n\\mathbf{X} ~ = ~ \n\\begin{bmatrix}\nX_1 \\\\\nX_2 \\\\\n\\end{bmatrix}\n$$\n\n### Mean Vector ###\nThe *mean vector* of $\\mathbf{X}$ is defined as\n$$\n\\boldsymbol{\\mu} ~ = ~ \n\\begin{bmatrix}\nE(X_1) \\\\\nE(X_2) \\\\\n\\end{bmatrix}\n$$\n\n### Covariance Matrix ###\nThe *covariance matrix* of $\\mathbf{X}$ is the $2\\times2$ matrix $\\boldsymbol{\\Sigma}$ whose $(i, j)$th element is $Cov(X_i, X_j)$. By properties of covariance,\n\n$$\n\\boldsymbol{\\Sigma} ~ = ~ \n\\begin{bmatrix}\nVar(X_1) & Cov(X_1, X_2) \\\\\nCov(X_1, X_2) & Var(X_2)\n\\end{bmatrix}\n$$\n\nEvery covariance matrix is symmetric, and the elements along its main diagonal are non-negative. Covariance matrices have another property that isn't easy to spot just by looking. As you will soon see in class, there is a relation between $Cov(X_1, X_2)$, $Var(X_1)$, and $Var(X_2)$; the  relation implies that only positive semi-definite matrices can be covariance matrices. But you don't have to worry about that in this lab.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"## The Normal Density Function ##\nThe normal density function can be written in many ways. Let's look at how we have written it thus far. The goal is to help you focus on the most important aspects of the density function without getting caught up in details.\n\n### Quadratic in the Exponent  ###\nThe normal $(\\mu, \\sigma^2)$ density has a quadratic expression in the exponent.\n\n$$\nf(x) ~ = ~ \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} \\big{(} \\frac{x-\\mu}{\\sigma} \\big{)}^2} ~ = ~ C e^{-\\big{[}\\frac{1}{2}(ax^2 + bx + c)\\big{]}}, ~~~~~~ -\\infty < x < \\infty\n$$\n\nwhere $C$, $a$, $b$, and $c$ are constants with $a > 0$. \n\nThe quadratic expression $\\frac{1}{2}(ax^2 + bx + c)$ determines the shape of the density. As you know, $C$ just makes the density integrate to 1.\n\nIf you have a density function and are trying to decide whether it is a normal density, ignore the constants and just look in the exponent. If what you see there is a quadratic, the density is normal. You can work out the mean and SD by methods such as \"completing the square\", but that algebra exercise is not part of this lab.\n\n### Centering ###\nThe focus of the lab is on the form of the normal density function and the shape of the density surface of two jointly normal variables. Shifting the variables only affects location, not the shape. So we will start with centered variables, that is, variables with expectation 0. At the end of the lab we will make a straightforward modification for the case of non-zero means. For now, just assume $\\mu = 0$, so that\n\n$$\nf(x) ~ = ~ Ce^{-\\frac{1}{2}ax^2}, ~~~~~~ -\\infty < x < \\infty\n$$","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"\\newpage\n\n## Section 1. Independent Standard Normal Variables ##","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"Let $Z_1, Z_2$ be i.i.d. standard normal. As you know, their joint density is\n\n$$\nf(z_1, z_2) ~ = ~ \\frac{1}{2\\pi} e^{-\\frac{1}{2}(z_1^2 + z_2^2)}, ~~~~~ -\\infty < z_1, z_2 < \\infty\n$$\n\nNotice that the expression in the exponent is quadratic in $z_1$ and $z_2$. It's a particularly simple quadratic – there are no $z_1z_2$, $z_1$, or $z_2$ terms. That is because $Z_1$ and $Z_2$ are independent and in standard units.\n\nIn this part of the lab you will learn how to rewrite $f$ using matrices.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"### 1a) The Familiar Form ###\nRun the cell below. It contains the code used in the textbook to plot $f$. Notice the use of `np.pi` for $\\pi$ and `np.exp` for exponentiation.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"def indep_standard_normals(x, y):\n    return 1/(2*np.pi) * np.exp(-0.5*(x**2 + y**2))\n\nPlot_3d((-4, 4), (-4, 4), indep_standard_normals,\n        rstride=4, cstride=4)\nplt.title('Joint Density of $Z_1$ and $Z_2$');","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1b) The Joint Density in `SymPy` ###\n\nRecall from a previous lab that you can do symbolic math in Python using `SymPy`. Run the cell below to create two symbols `z_1` and `z_2`.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"z_1 = Symbol('z_1')\nz_2 = Symbol('z_2')","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Construct the `SymPy`expression `f` to have the value $f(z_1, z_2)$ for the joint density $f$ of two i.i.d. standard normal variables. Remember that `SymPy` recognizes `pi` as $\\pi$ and `exp(x)` as $e^x$.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"# f(z_1, z_2)\n\nf = ...\nf","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As you saw when you used `SymPy` before, it doesn't always display functions in the way that's most natural for probability theory. That's OK. It happens sometimes when we use symbolic math programs. \n\nLet `function_name` be a `SymPy` expression involving two symbols `x` and `y`. Recall that you can display the integral of `function_name` over a region in the plane by using:\n\n`Integral(function_name, (x, lower_x, upper_x), (y, lower_y, upper_y))`\n\nwhere `lower` and `upper` are the lower and upper limits of integration. \n\nRemember also that `SymPy` uses the symbol `oo` (two lower-case letter o's) for $\\infty$ and `-oo` for $-\\infty$.\n\nDisplay the integral of the function $f$ over the entire plane.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"total_integral = ...\ntotal_integral","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Recall that you can compute the value of the definite integral by using `.doit()`. Run the cell below to check that `SymPy` gets the right answer.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"total_integral.doit()","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1c) Matrices in `SymPy` ###\nLet\n$$\n\\mathbf{Z} ~ = ~\n\\begin{bmatrix}\nZ_1 \\\\\nZ_2\n\\end{bmatrix}\n$$\nand let\n$$\n\\mathbf{z} ~ = ~\n\\begin{bmatrix}\nz_1 \\\\\nz_2\n\\end{bmatrix}\n$$\nbe a generic value of $\\mathbf{Z}$.\n\nRecall the formula for the joint density of $\\mathbf{Z}$:\n\n$$\nf(z_1, z_2) ~ = ~ \\frac{1}{2\\pi} e^{-\\frac{1}{2}(z_1^2 + z_2^2)}\n$$\n\nWe will use the notation $\\mathbf{M}^T$ for the transpose of a matrix $\\mathbf{M}$. It is clear by algebra that\n\n$$\nf(\\mathbf{z}) \n~ = ~ \\frac{1}{(\\sqrt{2\\pi})^2} \\exp(-\\frac{1}{2}\\mathbf{z}^T \\mathbf{z})\n$$\n\nLet's see how to calculate $\\mathbf{z}^T\\mathbf{z}$ in `SymPy`.\n\nThe function `Matrix` converts a list into a column matrix. The method `.T` returns the transpose of the matrix.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"z = Matrix([z_1, z_2])\nz","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"z.T","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Compute $\\mathbf{z}^T \\mathbf{z}$ in the cell below. The ordinary multiplication symbol `*` works for matrix multiplication in `SymPy`.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"...","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1d) The Quadratic and the Covariance Matrix ###\nYou have now checked in a couple of ways that if the two-dimensional random vector $\\mathbf{Z}$ consists of i.i.d. standard normal variables, then the joint density of $\\mathbf{Z}$ is\n\n$$\nf(\\mathbf{z}) \n~ = ~ \\frac{1}{(\\sqrt{2\\pi})^2} \\exp(-\\frac{1}{2}\\mathbf{z}^T \\mathbf{z})\n$$\n\nThe key point to keep in mind:\n\nWhen $\\mathbf{Z}$ is i.i.d. standard normal, **the quadratic in the exponent** is defined as $\\frac{1}{2}\\mathbf{z}^T\\mathbf{z}$ (without the minus sign). That is, the quadratic is half the dot product of the vector $\\mathbf{z}$ with itself.\n\nBecause $Z_1$ and $Z_2$ are i.i.d. standard normal, the covariance matrix of $\\mathbf{Z}$ is the two-dimensional identity matrix $\\mathbf{I}_2$, which `SymPy` has chosen to name as follows:","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"eye(2)","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After you've stopped laughing, check that `SymPy` gives the right answers for the following. We are using the notation $\\det(\\mathbf{M})$ for the determinant of $\\mathbf{M}$.\n\n(i) $\\mathbf{I}_2^{-1}$\n\n(ii) $\\det(\\mathbf{I}_2)$\n\n(iii) $\\mathbf{z}^T \\mathbf{I}_2^{-1} \\mathbf{z}$\n\nFor a `SymPy` matrix `mat`:\n- `mat.T` evaluates to the transpose\n- `mat.det()` evaluates to the determinant\n- `mat.inv()` evaluates to the inverse","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"# (i)\n\n...","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# (ii)\n\n...","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# (iii)\n\n...","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"tags":[],"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You showed earlier that we can rewrite the i.i.d. standard normal joint density as\n\n$$\nf(\\mathbf{z}) \n~ = ~ \\frac{1}{(\\sqrt{2\\pi})^2} \\exp(-\\frac{1}{2}\\mathbf{z}^T \\mathbf{z})\n$$\n\nNow you can write another equivalent form:\n\n$$\nf(\\mathbf{z}) \n~ = ~ \\frac{1}{(\\sqrt{2\\pi})^2\\sqrt{\\det(\\mathbf{I}_2)}} \\exp(-\\frac{1}{2}\\mathbf{z}^T \\mathbf{I}_2^{-1} \\mathbf{z})\n$$\n\nWe say that $\\mathbf{Z}$ is has the **centered bivariate normal distribution with covariance matrix $\\mathbf{I}_2$**. \n\nTo see why we complicating matters by throwing in a bunch of silly multiplications by 1, continue with the lab.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"\\newpage\n\n## Section 2: Changing Units – The Effect on the Quadratic  ###\nLet $a$ and $b$ be non-zero constants. Let $V_1 = aZ_1$ and $V_2 = bZ_2$, and let\n\n$$\n\\mathbf{V} ~ = ~ \n\\begin{bmatrix}\nV_1 \\\\\nV_2\n\\end{bmatrix}\n$$\n\nLet $f_\\mathbf{V}$ be the joint density of $V_1$ and $V_2$. We will say for short that $f_\\mathbf{V}$ is the joint density of $\\mathbf{V}$.\n\nThe goal of this part of the lab is to begin to write the formula for $f_\\mathbf{V}$ in terms of matrices and to understand the quadratic component.\n\nMuch of the work in this part can be done easily by hand. But setting up the matrix framework in `SymPy`, as you are being asked to do below, will make some of the subsequent parts easier.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"### 2a) [ON PAPER] Joint Density of a Linear Transformation ###\n\nWe started the lab with the definition \n\n$$\nf(z_1, z_2) ~ = ~ \\frac{1}{2\\pi} e^{-\\frac{1}{2}(z_1^2 + z_2^2)}\n$$\n\nBy extending the argument for linear change of variable in one dimension, find a formula for $f_{\\mathbf{V}}(v_1, v_2)$ in terms of $f$, $a$, $b$ and of course $v_1$ and $v_2$. Be careful – make sure that your density can't be negative.\n\nExplain why your formula works. \n\nThen fill in the three blanks below. \n\n$$\nf_{\\mathbf{V}}(v_1, v_2) ~ = ~ \nf \\big{(} \\underline{ ~ (i) ~ }, \\underline{ ~ (ii) ~ } \\big{)} \\cdot \\frac{1}{\\underline{ ~ (iii) ~ }}\n$$","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"### 2b) Image and Preimage ###\nWe started with non-zero constants $a$ and $b$, the variables $V_1 = aZ_1$ and $V_2 = bZ_2$, and the random vector\n\n$$\n\\mathbf{V} ~ = ~ \n\\begin{bmatrix}\nV_1 \\\\\nV_2\n\\end{bmatrix}\n$$\n\n$\\mathbf{V}$ is a linear transformation of $\\mathbf{Z}$, so $\\mathbf{V} = \\mathbf{A}\\mathbf{Z}$ where $\\mathbf{A}$ is a matrix of coefficients.\n\nOn the space of possible values, let vectors $\\mathbf{z}$ and $\\mathbf{v}$ be such that\n\n$$\n\\mathbf{v} ~ = ~ \\mathbf{A}\\mathbf{z}\n$$\n\nWe will call $\\mathbf{v}$ the *image* of $\\mathbf{z}$ under the linear tranformation by $\\mathbf{A}$, and we will call $\\mathbf{z}$ the *preimage* of $\\mathbf{v}$.\n\nInformally, $\\mathbf{z}$ is the point that leads to $\\mathbf{v}$ via the linear transformation $\\mathbf{A}$.\n\nIn this exercise you will establish the relation between the preimage and the quadratic in the exponent. First, run the cell below create some symbols.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"a = Symbol('a')\nb = Symbol('b')\nv_1 = Symbol('v_1')\nv_2 = Symbol('v_2')","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You can use `Matrix` to create a matrix by rows, providing a list of lists as the argument, as follows. \n\nHere is a matrix with just one row. Notice the contrast with the way of producing a column.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"Matrix([[1,2]]), Matrix([1, 2])","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Matrix([[1, 2], [3, 4]])","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the matrix $\\mathbf{A}$ in `SymPy`. Call it `coeffs` as a reminder that it contains the coefficients of the linear transformation.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"coeffs = ...\ncoeffs","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Remember that you have already defined\n$\\mathbf{z} = \n\\begin{bmatrix}\nz_1 \\\\\nz_2\n\\end{bmatrix}$\n\nFind the image of $\\mathbf{z}$. This is a check to see that your definition of `coeffs` is correct.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"image_of_z = ...\nimage_of_z","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define\n$\\mathbf{v} = \n\\begin{bmatrix}\nv_1 \\\\\nv_2\n\\end{bmatrix}$","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"v = ...\nv","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Find the preimage of $\\mathbf{v}$. Make sure your answer is a column vector. You might want to use some scratch paper first.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"preimage_of_v = ...\npreimage_of_v","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Find the dot product of this preimage with itself.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"...","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Go back and look at your answer to **2a**. \n\n**True or false:**\n\nIn the formula for the joint density $f_\\mathbf{V}$ at the point $\\mathbf{v}$, the quadratic in the exponent is half the dot product of the preimage of $\\mathbf{v}$ with itself.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"\n**Your answer here:**\n","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true}},{"cell_type":"markdown","source":"### 2c) Covariance Matrix of $\\mathbf{V}$ ###\n\nLet $\\boldsymbol{\\Sigma}_\\mathbf{V}$ be the covariance matrix of $\\mathbf{V}$. In the cell below, define $\\boldsymbol{\\Sigma}_\\mathbf{V}$ in terms of $a$ and $b$.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"Sigma_V = Matrix([... , ...])\nSigma_V","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Find $\\boldsymbol{\\Sigma}_\\mathbf{V}^{-1}$.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"...","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Find $\\mathbf{v}^T \\boldsymbol{\\Sigma}_\\mathbf{V}^{-1} \\mathbf{v}$.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"...","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This shows that in the formula for the joint density of $f_\\mathbf{V}$ at the point $\\mathbf{v}$, the quadratic in the exponent can be written as\n\n$$\n\\frac{1}{2} \\mathbf{v}^T \\boldsymbol{\\Sigma}_\\mathbf{V}^{-1} \\mathbf{v}\n$$\n\nThis form is useful because it is expressed directly in terms of $\\mathbf{v}$ and not the preimage. ","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"\\newpage","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"## Section 3. Changing Units: The Effect on the Constant of Integration ##\nTo complete the formula for $f_\\mathbf{V}$, we need the constant of integration.\n\nRecall from your linear algebra class that in two dimensions, the determinant of a matrix is the area of the parallelogram formed by the images of the two unit vectors under the transformation by that matrix.\n\nLet's confirm this for the transformation in Part 2.\n\n### 3a) Transformation of the Unit Square ###\nDefine the two unit vectors. Remember that they should be column vectors.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"tags":[]}},{"cell_type":"code","source":"unit_vector_1 = ...\nunit_vector_2 = ...\nunit_vector_1, unit_vector_2","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Find the images of the unit vectors under the tranformation by `coeffs`.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"image_1 = ...\nimage_2 = ...\nimage_1, image_2","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Run the cell below to see the unit square and the resulting parallelogram when $a=2$ and $b=3$. For this linear transformation, the parallelogram is a rectangle.. The area of the unit square has gone up by a factor of $ab = 6$.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"unit_square_to_rectangle(a = 2, b = 3)","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Suppose $a=2$ and $b=-3$. Run the cell below. What is the area of the rectangle bounded by the transformed unit vectors? Is $ab$ the correct formula for the area? Write your answer in the subsequent cell.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"unit_square_to_rectangle(a = 2, b = -3)","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n**Your answer here**","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true}},{"cell_type":"markdown","source":"### 3b) [ON PAPER] Two Related Determinants ###\nIn Part 2 you created the `SymPy` matrix `coeffs` to be the linear transformation in the equation $\\mathbf{V} = \\mathbf{AZ}$. You also created `Sigma_V` to be the covariance matrix of $\\mathbf{V}$.\n\n(i) Calculate $\\mathbf{AA}^T$ by hand and show that\n\n$$\n\\boldsymbol{\\Sigma}_\\mathbf{V} ~ = ~ \\mathbf{AA}^T\n$$\n\n(ii) Show that if $\\mathbf{z}$ is the preimage of $\\mathbf{v}$ then\n\n$$\n\\mathbf{z}^T\\mathbf{z} ~ = ~ \\mathbf{v}^T (\\mathbf{AA^T})^{-1} \\mathbf{v}\n~ = ~ \\mathbf{v}^T \\boldsymbol{\\Sigma}_\\mathbf{V}^{-1} \\mathbf{v}\n$$\n\n(iii) Use properties of determinants and the first fact above to explain why $\\det(\\boldsymbol{\\Sigma}_\\mathbf{V}) = (\\det(\\mathbf{A}))^2$. \n\n*Hint:* For two square matrices of order $n$ $\\mathbf{A}$ and $\\mathbf{B}$, $\\text{det}(\\mathbf{AB}) = \\text{det}(\\mathbf{A}) \\text{det}(\\mathbf{B})$","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"### 3c) The Determinant of the Covariance Matrix ###\n\nFind $\\det(\\boldsymbol{\\Sigma}_\\mathbf{V})$ in the cell below.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"...","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now look at what you put in Blank (iii) of **2a**, and fill in the blanks below.\n\nI filled Blank (iii) of **2a** with the $\\underline{~~~~~~~~~~~~~~~~}$ \nof the determinant of $\\mathbf{A}$, which is the same as the \n$\\underline{~~~~~~~~~~~~~~~~}$ \nof the determinant of $\\boldsymbol{\\Sigma_\\mathbf{V}}$.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"\n**Your answer here:**\n\n","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true}},{"cell_type":"markdown","source":"### 3d) [ON PAPER] A Reparametrization ###\n\nYour work in Parts 2 and 3 has shown that\n\n$$\nf_\\mathbf{V}(\\mathbf{v}) ~ = ~ \\frac{1}{(\\sqrt{2\\pi})^2 \\sqrt{\\det(\\boldsymbol{\\Sigma}_\\mathbf{V})} } \\exp \\big{(} -\\frac{1}{2} \\mathbf{v}^T \\boldsymbol{\\Sigma}_\\mathbf{V}^{-1} \\mathbf{v} \\big{)}\n$$\n\nThe joint density has been expressed in terms of the parameter $\\boldsymbol{\\Sigma}$, the covariance matrix. We say that $\\mathbf{V}$ has the **centered bivariate normal distribution with covariance matrix $\\boldsymbol{\\Sigma}_\\mathbf{V}$**.\n\nConfirm that the formula at the end of Part 1 is a special case of this one.\n\nThis way of expressing the joint density in terms of the covariance matrix extends to higher dimensions. The dimension 2 gets replaced by the new dimension $n$, but other than that, the formula remains exactly the same.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"### 3e) Visualization ###\nRun the cell below to see graphs of $f$ and $f_\\mathbf{V}$. As in **3a**, we have set $a=2$ and $b=3$. The bottom left panel shows 10 points picked independently according to $f$. The bottom right panel shows those 10 points transformed to create the corresponding 10 replications from $f_\\mathbf{V}$.\n\nAs you know, $f$ has circular symmetry: its level sets are circles. Those circles get transformed into ellipses whose axes are along the $v_1$ and $v_2$ axes. That is why the level sets $f_\\mathbf{V}$ are ellipses. Move the slider (slowly!) to the right to see the elongated shape.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"z_to_v(a=2, b=3, n=10)","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\\newpage","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"## Section 4: Introducing Dependence ##","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"Let $Z_1$ and $Z_2$ be i.i.d. standard normal as before. Now let $W_1 = Z_1$ and $W_2 = aZ_1 + bZ_2$. As before, both $a$ and $b$ are non-zero constants. \n\nLet \n$\\mathbf{W} = \n\\begin{bmatrix}\nW_1 \\\\\nW_2\n\\end{bmatrix}$. \n\nOur goal is to find the joint density $f_\\mathbf{W}$ at the generic point \n\n$\\mathbf{w} = \n\\begin{bmatrix}\nw_1 \\\\\nw_2\n\\end{bmatrix}$.\n\n### 4a) Marginals and Covariance ###\n\nAre the marginal distributions of $W_1$ and $W_2$ normal? Why or why not?","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"\n**Your answer here:**\n\n","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true}},{"cell_type":"markdown","source":"Construct the covariance matrix $\\boldsymbol{\\Sigma}_\\mathbf{W}$ of the random vector $\\mathbf{W}$. Use only the symbols `a` and `b`.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"Sigma_W = Matrix([..., ...])\nSigma_W","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Could $W_1$ and $W_2$ be independent? Explain your answer.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"\n**Your answer here:**\n\n","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true}},{"cell_type":"markdown","source":"### 4b) The Quadratic ###\n\nBy the same logic as in **2a**,\n$$\nf_\\mathbf{W}(\\mathbf{w}) ~ = ~ Cf(\\mathbf{z})\n$$\nwhere $\\mathbf{z}$ is the preimage of $\\mathbf{w}$ and $C$ is a positive constant.\n\nYou know that the quadratic in the exponent of $f(\\mathbf{z})$ is $\\frac{1}{2}\\mathbf{z}^T\\mathbf{z}$. In this exercise you will express that quadratic in terms of $\\mathbf{w}$ and $\\boldsymbol{\\Sigma}_\\mathbf{W}$.\n\n$\\mathbf{W} = \\mathbf{AZ}$ for some matrix $\\mathbf{A}$. Define $\\mathbf{A}$ in the cell below; call it `coeffs` as before.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"coeffs = ...\ncoeffs","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Check that your matrix is correct by finding the image of $\\mathbf{z}$ under the transformation by the matrix.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"...","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now run the cell below to define\n$\\mathbf{w} =  \n\\begin{bmatrix}\nw_1 \\\\\nw_2\n\\end{bmatrix}$","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"w_1 = Symbol('w_1')\nw_2 = Symbol('w_2')\n\nw = Matrix([w_1, w_2])\nw","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Find the preimage of $\\mathbf{w}$.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"preimage = ...\npreimage","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Find the dot product of the preimage with itself. The quadratic in the exponent of the joint density function is 1/2 times this dot product. ","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"preimage_dotproduct = ...\npreimage_dotproduct","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As in Part 2, this dot product is equal to $\\mathbf{w}^T \\boldsymbol{\\Sigma}_\\mathbf{W}^{-1} \\mathbf{w}$. This expression is called a *quadratic form*. \n\nTo show this, compute the quadratic form and don't worry if it doesn't look like the output of the cell above. Algebraic expressions can be written in many equivalent ways.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"quadratic_form = ...\nquadratic_form","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You saw in an earlier lab that the function `simplify` saves you the trouble of simplifying the algebra. But because there are multiple ways of simplifying algebraic expressions, there are also multiple simplification functions in `SymPy`. \n\nOne such function is `expand`, which does what you expect based on its name: it carries out all the multiplications and collects terms. Run the two cells below and compare the outputs.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"expand(preimage_dotproduct)","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"expand(quadratic_form)","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"What you have shown thus far is that the joint density of $\\mathbf{W}$ is given by\n$$\nf_\\mathbf{W}(\\mathbf{w}) ~ = ~ C \\exp (-\\frac{1}{2} \\mathbf{w}^T \\boldsymbol{\\Sigma}_\\mathbf{W}^{-1} \\mathbf{w})\n$$","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"### 4c) The Constant of Integration ###\nAs in Part 3, the constant $C$ has two factors. One factor is $(1/\\sqrt{2\\pi})^2$. The other is $1/s$ where $s$ is the area of the parallelogram formed by the transformed unit vectors.\n\nRemember that the transformation is determined by the matrix `coeffs`, and that the unit vectors are called `unit_vector_1` and `unit_vector_2`.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"coeffs, unit_vector_1, unit_vector_2","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Find the images of the unit vectors under the linear transformation.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"image_1 = ...\nimage_2 = ...\nimage_1, image_2","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The figure below shows the two image vectors and the resulting parallelogram in the case $a=2$ and $b=3$.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"unit_square_to_parallelogram(a = 2, b = 3)","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Run the cell below a few times with varying positive values of $a$ and $b$. Notice the geometry of how the parallelogram is formed: how are $a$ and $b$ connected with the vertices?","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"unit_square_to_parallelogram(a = 5, b = 1)","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"One of the vertices is always $(0, 0)$. In terms of $a$ and $b$, what are the other three vertices? It's fine to assume $a$ and $b$ are both positive, though it is not necessary.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"\n**Your answer here**","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true}},{"cell_type":"markdown","source":"Fill in the blanks:\n\nSupppose $a$ and $b$ are both positive. If we define the \"base\" of the parallelogram to be a vertical side of length b, then the \"height\" of the red parallelogram is always equal to $\\underline{~~~~~~~~}$. Therefore the area of the parallelogram is $\\underline{~~~~~~~~}$.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"\n**Your answer here:**\n\n","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true}},{"cell_type":"markdown","source":"Use `SymPy` and `Sigma_W` to find $\\det(\\boldsymbol{\\Sigma}_\\mathbf{W})$.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"...","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true,"jupyter":{"outputs_hidden":true},"trusted":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**True or False:** The area of the parallelogram is $\\sqrt{\\det(\\boldsymbol{\\Sigma}_\\mathbf{W})}$.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"\n**Your answer here:**\n","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true}},{"cell_type":"markdown","source":"### 4d) The Joint Density ###\nYou have shown that $\\mathbf{W}$ has the **centered bivariate normal density with covariance matrix $\\boldsymbol{\\Sigma}_\\mathbf{W}$**, given by\n\n$$\nf_\\mathbf{W}(\\mathbf{w}) ~ = ~ \\frac{1}{(\\sqrt{2\\pi})^2 \\sqrt{\\det(\\boldsymbol{\\Sigma}_\\mathbf{W})} } \\exp \\big{(} -\\frac{1}{2} \\mathbf{w}^T \\boldsymbol{\\Sigma}_\\mathbf{W}^{-1} \\mathbf{w} \\big{)}\n$$\n\nRun the cell below for graphs of $f$ and $f_\\mathbf{W}$. As before, we have set $a=2$ and $b=3$. Circles get transformed to ellipses as before, but now the axes of the ellipses are at an angle to the $w_1$ and $w_2$ axes.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"code","source":"z_to_w(a=2, b=3, n=10)","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"At this point you should be pretty confident that if we took some other centered linear transformation of $\\mathbf{Z}$, it too would have a joint density of the form that we have developed. We will do the general calculation in class. Because you have done this lab, you will quickly understand what the pieces of the general formula mean.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"## Endnote: $n$ Dimensions ##\nWe will discuss the details in class, but here is a summary that should come as no surprise.\n\nLet $\\mathbf{X} = \n\\begin{bmatrix}\nX_1 \\\\\nX_2 \\\\\n\\vdots \\\\\nX_n\n\\end{bmatrix}$\nbe a random vector.\n\n- For a symmetric positive definite $n \\times n$ matrix $\\boldsymbol{\\Sigma}$, the random vector $\\mathbf{X}$ has the centered multivariate normal distribution with covariance matrix $\\boldsymbol{\\Sigma}$ if the joint density function is given by\n\n$$\nf_{\\mathbf{X}}(\\mathbf{x}) ~ = ~ \\frac{1}{(\\sqrt{2\\pi})^n \\sqrt{\\det(\\boldsymbol{\\Sigma})} } \\exp \\big{(} -\\frac{1}{2} \\mathbf{x}^T \\boldsymbol{\\Sigma}^{-1} \\mathbf{x} \\big{)}\n$$\n\nThis is exactly the same as the formula you have developed in this lab, but now $n$ can be greater than 2.\n\n- Multivariate normal variables with mean vector $\\boldsymbol{\\mu}$ and covariance matrix $\\boldsymbol{\\Sigma}$ are just $Y_1, Y_2, \\ldots, Y_n$ where $Y_i = X_i + \\boldsymbol{\\mu}[i]$. Shifting doesn't change covariances or volumes. So\n\n$$\nf_{\\mathbf{Y}}(\\mathbf{y}) ~ = ~ f_{\\mathbf{X}}(\\mathbf{y} - \\boldsymbol{\\mu})\n~ = ~ \\frac{1}{(\\sqrt{2\\pi})^n \\sqrt{\\det(\\boldsymbol{\\Sigma})} } \\exp \\big{(} -\\frac{1}{2} (\\mathbf{y} - \\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{y} - \\boldsymbol{\\mu}) \\big{)}\n$$\n\nWe will see that if the joint distribution of a random vector is multivariate normal then all the marginals are normal.\n\nHowever, we will also see that it is possible to construct a random vector such that all the marginals are normal but the joint density is not multivariate normal.\n\nSo \"multivariate normal\" means more than \"all the marginals are normal.\" In the remainder of the course you will see the main properties of this joint distribution and develop the theory of multiple regression.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"## Conclusion ##\nYou have learned:\n- how to use `SymPy` for linear algebra\n- the formula for the multivariate normal joint density\n- where the pieces of the formula come from\n- what the joint density surface looks like in two dimensions\n- how the covariance matrix is related to the matrix of coefficients of the linear transformation","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":false}},{"cell_type":"markdown","source":"## Submission Instructions ##\n\nMany assignments throughout the course will have a written portion and a code portion. Please follow the directions below to properly submit both portions.\n\n### Written Portion ###\n*  Scan all the pages into a PDF. You can use any scanner or a phone using applications such as CamScanner. Please **DO NOT** simply take pictures using your phone. \n* Please start a new page for each question. If you have already written multiple questions on the same page, you can crop the image in CamScanner or fold your page over (the old-fashioned way). This helps expedite grading.\n* It is your responsibility to check that all the work on all the scanned pages is legible.\n* If you used $\\LaTeX$ to do the written portions, you do not need to do any scanning; you can just download the whole notebook as a PDF via LaTeX.\n\n### Code Portion ###\n* Save your notebook using `File > Save and Checkpoint`.\n* Generate a PDF file using `File > Download As > PDF via LaTeX`. This might take a few seconds and will automatically download a PDF version of this notebook.\n    * If you have issues, please post a follow-up on the general Lab 8 Ed thread.\n    \n### Submitting ###\n* Combine the PDFs from the written and code portions into one PDF. [Here](https://smallpdf.com/merge-pdf) is a useful tool for doing so. \n* Submit the assignment to Lab 8 on Gradescope. \n* **Make sure to assign each page of your pdf to the correct question.**\n* **It is your responsibility to verify that all of your work shows up in your final PDF submission.**\n\nIf you are having difficulties scanning, uploading, or submitting your work, please read the [Ed Thread](https://edstem.org/us/courses/62266/discussion/5191791) on this topic and post a follow-up on the general Lab 8 Ed thread.","metadata":{"#question":false,"#solution":false,"#staff":false,"#student":true}}]}